{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd6e47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import mindspore\n",
    "from mindspore import Tensor, dtype\n",
    "from mindspore import save_checkpoint\n",
    "from mindspore import Parameter\n",
    "model = torch.load(\"beit_base_patch16_224_pt22k_ft22k.pth\", map_location='cpu')['model']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3f5729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.attn.relative_position_bias_table\n",
      "blocks.0.attn.relative_position_index\n",
      "blocks.1.attn.relative_position_bias_table\n",
      "blocks.1.attn.relative_position_index\n",
      "blocks.2.attn.relative_position_bias_table\n",
      "blocks.2.attn.relative_position_index\n",
      "blocks.3.attn.relative_position_bias_table\n",
      "blocks.3.attn.relative_position_index\n",
      "blocks.4.attn.relative_position_bias_table\n",
      "blocks.4.attn.relative_position_index\n",
      "blocks.5.attn.relative_position_bias_table\n",
      "blocks.5.attn.relative_position_index\n",
      "blocks.6.attn.relative_position_bias_table\n",
      "blocks.6.attn.relative_position_index\n",
      "blocks.7.attn.relative_position_bias_table\n",
      "blocks.7.attn.relative_position_index\n",
      "blocks.8.attn.relative_position_bias_table\n",
      "blocks.8.attn.relative_position_index\n",
      "blocks.9.attn.relative_position_bias_table\n",
      "blocks.9.attn.relative_position_index\n",
      "blocks.10.attn.relative_position_bias_table\n",
      "blocks.10.attn.relative_position_index\n",
      "blocks.11.attn.relative_position_bias_table\n",
      "blocks.11.attn.relative_position_index\n"
     ]
    }
   ],
   "source": [
    "model_keys = []\n",
    "nums = 0.\n",
    "for key in model.keys():\n",
    "    if \"num_batches_tracked\" not in key:\n",
    "        model_keys.append(key)\n",
    "        nums += np.prod(model[key].shape)\n",
    "    if \"pos\" in key:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "172d1c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 768)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "prefix = \"model.\"\n",
    "for key in model_keys:\n",
    "    name2weight = {}\n",
    "    if \"bn\" in key or \"norm\" in key or \"ln\" in key:\n",
    "        if \"weight\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\".weight\", \".gamma\")\n",
    "        elif \"bias\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\".bias\", \".beta\")\n",
    "        elif \"mean\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\"running_mean\", \"moving_mean\")\n",
    "        elif \"var\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\"running_var\", \"moving_variance\")\n",
    "        \n",
    "        name2weight[\"data\"] = Parameter(Tensor(model[key].numpy(), dtype.float32),requires_grad=True) \n",
    "        weights.append(name2weight)\n",
    "    elif \"qkv\" in key:\n",
    "        key_q = prefix +  key.replace(\"qkv\", \"q\")\n",
    "        key_k = prefix +  key.replace(\"qkv\", \"k\")\n",
    "        key_v = prefix + key.replace(\"qkv\", \"v\")\n",
    "        shape = model[key].shape[0]//3\n",
    "        weight = Parameter(Tensor(model[key].numpy(), dtype.float32),requires_grad=True) \n",
    "        weight_q = weight[:shape]\n",
    "        weight_k = weight[shape:shape*2]\n",
    "        weight_v = weight[shape*2:]\n",
    "        weights.append({\"name\":key_q, \"data\": weight_q})\n",
    "        weights.append({\"name\":key_k, \"data\": weight_k})\n",
    "        weights.append({\"name\":key_v, \"data\": weight_v})\n",
    "    elif \"q_bias\" in key:\n",
    "        name2weight[\"name\"] = prefix + key.replace(\"q_bias\", \"q.bias\")\n",
    "        name2weight[\"data\"] = Parameter(Tensor(model[key].numpy(), dtype.float32),requires_grad=True)\n",
    "        weights.append(name2weight)\n",
    "    elif \"v_bias\" in key:\n",
    "        name2weight[\"name\"] = prefix + key.replace(\"v_bias\", \"v.bias\")\n",
    "        name2weight[\"data\"] = Parameter(Tensor(model[key].numpy(), dtype.float32),requires_grad=True)\n",
    "        weights.append(name2weight)\n",
    "    elif \"head\" in key:\n",
    "        # we don't need classfier layer\n",
    "        pass\n",
    "    else:\n",
    "        dd = dtype.float32\n",
    "        if \"relative_position_index\" in key:\n",
    "            dd = dtype.int32\n",
    "        weight = Parameter(Tensor(model[key].numpy(), dd),requires_grad=True)\n",
    "        key = prefix + key\n",
    "        weights.append({\"name\": key, \"data\": weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a079bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.cls_token (1, 1, 768)\n",
      "model.patch_embed.proj.weight (768, 3, 16, 16)\n",
      "model.patch_embed.proj.bias (768,)\n",
      "model.blocks.0.gamma_1 (768,)\n",
      "model.blocks.0.gamma_2 (768,)\n",
      "model.blocks.0.norm1.gamma (768,)\n",
      "model.blocks.0.norm1.beta (768,)\n",
      "model.blocks.0.attn.q.bias (768,)\n",
      "model.blocks.0.attn.v.bias (768,)\n",
      "model.blocks.0.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.0.attn.relative_position_index (197, 197)\n",
      "model.blocks.0.attn.q.weight (768, 768)\n",
      "model.blocks.0.attn.k.weight (768, 768)\n",
      "model.blocks.0.attn.v.weight (768, 768)\n",
      "model.blocks.0.attn.proj.weight (768, 768)\n",
      "model.blocks.0.attn.proj.bias (768,)\n",
      "model.blocks.0.norm2.gamma (768,)\n",
      "model.blocks.0.norm2.beta (768,)\n",
      "model.blocks.0.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.0.mlp.fc1.bias (3072,)\n",
      "model.blocks.0.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.0.mlp.fc2.bias (768,)\n",
      "model.blocks.1.gamma_1 (768,)\n",
      "model.blocks.1.gamma_2 (768,)\n",
      "model.blocks.1.norm1.gamma (768,)\n",
      "model.blocks.1.norm1.beta (768,)\n",
      "model.blocks.1.attn.q.bias (768,)\n",
      "model.blocks.1.attn.v.bias (768,)\n",
      "model.blocks.1.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.1.attn.relative_position_index (197, 197)\n",
      "model.blocks.1.attn.q.weight (768, 768)\n",
      "model.blocks.1.attn.k.weight (768, 768)\n",
      "model.blocks.1.attn.v.weight (768, 768)\n",
      "model.blocks.1.attn.proj.weight (768, 768)\n",
      "model.blocks.1.attn.proj.bias (768,)\n",
      "model.blocks.1.norm2.gamma (768,)\n",
      "model.blocks.1.norm2.beta (768,)\n",
      "model.blocks.1.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.1.mlp.fc1.bias (3072,)\n",
      "model.blocks.1.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.1.mlp.fc2.bias (768,)\n",
      "model.blocks.2.gamma_1 (768,)\n",
      "model.blocks.2.gamma_2 (768,)\n",
      "model.blocks.2.norm1.gamma (768,)\n",
      "model.blocks.2.norm1.beta (768,)\n",
      "model.blocks.2.attn.q.bias (768,)\n",
      "model.blocks.2.attn.v.bias (768,)\n",
      "model.blocks.2.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.2.attn.relative_position_index (197, 197)\n",
      "model.blocks.2.attn.q.weight (768, 768)\n",
      "model.blocks.2.attn.k.weight (768, 768)\n",
      "model.blocks.2.attn.v.weight (768, 768)\n",
      "model.blocks.2.attn.proj.weight (768, 768)\n",
      "model.blocks.2.attn.proj.bias (768,)\n",
      "model.blocks.2.norm2.gamma (768,)\n",
      "model.blocks.2.norm2.beta (768,)\n",
      "model.blocks.2.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.2.mlp.fc1.bias (3072,)\n",
      "model.blocks.2.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.2.mlp.fc2.bias (768,)\n",
      "model.blocks.3.gamma_1 (768,)\n",
      "model.blocks.3.gamma_2 (768,)\n",
      "model.blocks.3.norm1.gamma (768,)\n",
      "model.blocks.3.norm1.beta (768,)\n",
      "model.blocks.3.attn.q.bias (768,)\n",
      "model.blocks.3.attn.v.bias (768,)\n",
      "model.blocks.3.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.3.attn.relative_position_index (197, 197)\n",
      "model.blocks.3.attn.q.weight (768, 768)\n",
      "model.blocks.3.attn.k.weight (768, 768)\n",
      "model.blocks.3.attn.v.weight (768, 768)\n",
      "model.blocks.3.attn.proj.weight (768, 768)\n",
      "model.blocks.3.attn.proj.bias (768,)\n",
      "model.blocks.3.norm2.gamma (768,)\n",
      "model.blocks.3.norm2.beta (768,)\n",
      "model.blocks.3.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.3.mlp.fc1.bias (3072,)\n",
      "model.blocks.3.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.3.mlp.fc2.bias (768,)\n",
      "model.blocks.4.gamma_1 (768,)\n",
      "model.blocks.4.gamma_2 (768,)\n",
      "model.blocks.4.norm1.gamma (768,)\n",
      "model.blocks.4.norm1.beta (768,)\n",
      "model.blocks.4.attn.q.bias (768,)\n",
      "model.blocks.4.attn.v.bias (768,)\n",
      "model.blocks.4.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.4.attn.relative_position_index (197, 197)\n",
      "model.blocks.4.attn.q.weight (768, 768)\n",
      "model.blocks.4.attn.k.weight (768, 768)\n",
      "model.blocks.4.attn.v.weight (768, 768)\n",
      "model.blocks.4.attn.proj.weight (768, 768)\n",
      "model.blocks.4.attn.proj.bias (768,)\n",
      "model.blocks.4.norm2.gamma (768,)\n",
      "model.blocks.4.norm2.beta (768,)\n",
      "model.blocks.4.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.4.mlp.fc1.bias (3072,)\n",
      "model.blocks.4.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.4.mlp.fc2.bias (768,)\n",
      "model.blocks.5.gamma_1 (768,)\n",
      "model.blocks.5.gamma_2 (768,)\n",
      "model.blocks.5.norm1.gamma (768,)\n",
      "model.blocks.5.norm1.beta (768,)\n",
      "model.blocks.5.attn.q.bias (768,)\n",
      "model.blocks.5.attn.v.bias (768,)\n",
      "model.blocks.5.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.5.attn.relative_position_index (197, 197)\n",
      "model.blocks.5.attn.q.weight (768, 768)\n",
      "model.blocks.5.attn.k.weight (768, 768)\n",
      "model.blocks.5.attn.v.weight (768, 768)\n",
      "model.blocks.5.attn.proj.weight (768, 768)\n",
      "model.blocks.5.attn.proj.bias (768,)\n",
      "model.blocks.5.norm2.gamma (768,)\n",
      "model.blocks.5.norm2.beta (768,)\n",
      "model.blocks.5.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.5.mlp.fc1.bias (3072,)\n",
      "model.blocks.5.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.5.mlp.fc2.bias (768,)\n",
      "model.blocks.6.gamma_1 (768,)\n",
      "model.blocks.6.gamma_2 (768,)\n",
      "model.blocks.6.norm1.gamma (768,)\n",
      "model.blocks.6.norm1.beta (768,)\n",
      "model.blocks.6.attn.q.bias (768,)\n",
      "model.blocks.6.attn.v.bias (768,)\n",
      "model.blocks.6.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.6.attn.relative_position_index (197, 197)\n",
      "model.blocks.6.attn.q.weight (768, 768)\n",
      "model.blocks.6.attn.k.weight (768, 768)\n",
      "model.blocks.6.attn.v.weight (768, 768)\n",
      "model.blocks.6.attn.proj.weight (768, 768)\n",
      "model.blocks.6.attn.proj.bias (768,)\n",
      "model.blocks.6.norm2.gamma (768,)\n",
      "model.blocks.6.norm2.beta (768,)\n",
      "model.blocks.6.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.6.mlp.fc1.bias (3072,)\n",
      "model.blocks.6.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.6.mlp.fc2.bias (768,)\n",
      "model.blocks.7.gamma_1 (768,)\n",
      "model.blocks.7.gamma_2 (768,)\n",
      "model.blocks.7.norm1.gamma (768,)\n",
      "model.blocks.7.norm1.beta (768,)\n",
      "model.blocks.7.attn.q.bias (768,)\n",
      "model.blocks.7.attn.v.bias (768,)\n",
      "model.blocks.7.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.7.attn.relative_position_index (197, 197)\n",
      "model.blocks.7.attn.q.weight (768, 768)\n",
      "model.blocks.7.attn.k.weight (768, 768)\n",
      "model.blocks.7.attn.v.weight (768, 768)\n",
      "model.blocks.7.attn.proj.weight (768, 768)\n",
      "model.blocks.7.attn.proj.bias (768,)\n",
      "model.blocks.7.norm2.gamma (768,)\n",
      "model.blocks.7.norm2.beta (768,)\n",
      "model.blocks.7.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.7.mlp.fc1.bias (3072,)\n",
      "model.blocks.7.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.7.mlp.fc2.bias (768,)\n",
      "model.blocks.8.gamma_1 (768,)\n",
      "model.blocks.8.gamma_2 (768,)\n",
      "model.blocks.8.norm1.gamma (768,)\n",
      "model.blocks.8.norm1.beta (768,)\n",
      "model.blocks.8.attn.q.bias (768,)\n",
      "model.blocks.8.attn.v.bias (768,)\n",
      "model.blocks.8.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.8.attn.relative_position_index (197, 197)\n",
      "model.blocks.8.attn.q.weight (768, 768)\n",
      "model.blocks.8.attn.k.weight (768, 768)\n",
      "model.blocks.8.attn.v.weight (768, 768)\n",
      "model.blocks.8.attn.proj.weight (768, 768)\n",
      "model.blocks.8.attn.proj.bias (768,)\n",
      "model.blocks.8.norm2.gamma (768,)\n",
      "model.blocks.8.norm2.beta (768,)\n",
      "model.blocks.8.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.8.mlp.fc1.bias (3072,)\n",
      "model.blocks.8.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.8.mlp.fc2.bias (768,)\n",
      "model.blocks.9.gamma_1 (768,)\n",
      "model.blocks.9.gamma_2 (768,)\n",
      "model.blocks.9.norm1.gamma (768,)\n",
      "model.blocks.9.norm1.beta (768,)\n",
      "model.blocks.9.attn.q.bias (768,)\n",
      "model.blocks.9.attn.v.bias (768,)\n",
      "model.blocks.9.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.9.attn.relative_position_index (197, 197)\n",
      "model.blocks.9.attn.q.weight (768, 768)\n",
      "model.blocks.9.attn.k.weight (768, 768)\n",
      "model.blocks.9.attn.v.weight (768, 768)\n",
      "model.blocks.9.attn.proj.weight (768, 768)\n",
      "model.blocks.9.attn.proj.bias (768,)\n",
      "model.blocks.9.norm2.gamma (768,)\n",
      "model.blocks.9.norm2.beta (768,)\n",
      "model.blocks.9.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.9.mlp.fc1.bias (3072,)\n",
      "model.blocks.9.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.9.mlp.fc2.bias (768,)\n",
      "model.blocks.10.gamma_1 (768,)\n",
      "model.blocks.10.gamma_2 (768,)\n",
      "model.blocks.10.norm1.gamma (768,)\n",
      "model.blocks.10.norm1.beta (768,)\n",
      "model.blocks.10.attn.q.bias (768,)\n",
      "model.blocks.10.attn.v.bias (768,)\n",
      "model.blocks.10.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.10.attn.relative_position_index (197, 197)\n",
      "model.blocks.10.attn.q.weight (768, 768)\n",
      "model.blocks.10.attn.k.weight (768, 768)\n",
      "model.blocks.10.attn.v.weight (768, 768)\n",
      "model.blocks.10.attn.proj.weight (768, 768)\n",
      "model.blocks.10.attn.proj.bias (768,)\n",
      "model.blocks.10.norm2.gamma (768,)\n",
      "model.blocks.10.norm2.beta (768,)\n",
      "model.blocks.10.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.10.mlp.fc1.bias (3072,)\n",
      "model.blocks.10.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.10.mlp.fc2.bias (768,)\n",
      "model.blocks.11.gamma_1 (768,)\n",
      "model.blocks.11.gamma_2 (768,)\n",
      "model.blocks.11.norm1.gamma (768,)\n",
      "model.blocks.11.norm1.beta (768,)\n",
      "model.blocks.11.attn.q.bias (768,)\n",
      "model.blocks.11.attn.v.bias (768,)\n",
      "model.blocks.11.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.11.attn.relative_position_index (197, 197)\n",
      "model.blocks.11.attn.q.weight (768, 768)\n",
      "model.blocks.11.attn.k.weight (768, 768)\n",
      "model.blocks.11.attn.v.weight (768, 768)\n",
      "model.blocks.11.attn.proj.weight (768, 768)\n",
      "model.blocks.11.attn.proj.bias (768,)\n",
      "model.blocks.11.norm2.gamma (768,)\n",
      "model.blocks.11.norm2.beta (768,)\n",
      "model.blocks.11.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.11.mlp.fc1.bias (3072,)\n",
      "model.blocks.11.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.11.mlp.fc2.bias (768,)\n",
      "model.fc_norm.gamma (768,)\n",
      "model.fc_norm.beta (768,)\n",
      "model.head.weight (1000, 768)\n",
      "model.head.bias (1000,)\n"
     ]
    }
   ],
   "source": [
    "weights_out = []\n",
    "for weight in weights:\n",
    "    weight_out = {}\n",
    "    name = weight[\"name\"]\n",
    "    weight_out[\"name\"] = name\n",
    "    weight_out[\"data\"] = weight[\"data\"]\n",
    "    weights_out.append(weight_out)\n",
    "    print(weight_out[\"name\"], weight_out['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "58e81d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(weights_out, \"beit_base_patch16_224_pt22k_ft22k.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7375f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c673f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.cls_token (1, 1, 768)\n",
      "model.patch_embed.proj.weight (768, 3, 16, 16)\n",
      "model.patch_embed.proj.bias (768,)\n",
      "model.blocks.0.gamma_1 (768,)\n",
      "model.blocks.0.gamma_2 (768,)\n",
      "model.blocks.0.norm1.gamma (768,)\n",
      "model.blocks.0.norm1.beta (768,)\n",
      "model.blocks.0.attn.q.bias (768,)\n",
      "model.blocks.0.attn.v.bias (768,)\n",
      "model.blocks.0.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.0.attn.relative_position_index (197, 197)\n",
      "model.blocks.0.attn.q.weight (768, 768)\n",
      "model.blocks.0.attn.k.weight (768, 768)\n",
      "model.blocks.0.attn.v.weight (768, 768)\n",
      "model.blocks.0.attn.proj.weight (768, 768)\n",
      "model.blocks.0.attn.proj.bias (768,)\n",
      "model.blocks.0.norm2.gamma (768,)\n",
      "model.blocks.0.norm2.beta (768,)\n",
      "model.blocks.0.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.0.mlp.fc1.bias (3072,)\n",
      "model.blocks.0.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.0.mlp.fc2.bias (768,)\n",
      "model.blocks.1.gamma_1 (768,)\n",
      "model.blocks.1.gamma_2 (768,)\n",
      "model.blocks.1.norm1.gamma (768,)\n",
      "model.blocks.1.norm1.beta (768,)\n",
      "model.blocks.1.attn.q.bias (768,)\n",
      "model.blocks.1.attn.v.bias (768,)\n",
      "model.blocks.1.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.1.attn.relative_position_index (197, 197)\n",
      "model.blocks.1.attn.q.weight (768, 768)\n",
      "model.blocks.1.attn.k.weight (768, 768)\n",
      "model.blocks.1.attn.v.weight (768, 768)\n",
      "model.blocks.1.attn.proj.weight (768, 768)\n",
      "model.blocks.1.attn.proj.bias (768,)\n",
      "model.blocks.1.norm2.gamma (768,)\n",
      "model.blocks.1.norm2.beta (768,)\n",
      "model.blocks.1.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.1.mlp.fc1.bias (3072,)\n",
      "model.blocks.1.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.1.mlp.fc2.bias (768,)\n",
      "model.blocks.2.gamma_1 (768,)\n",
      "model.blocks.2.gamma_2 (768,)\n",
      "model.blocks.2.norm1.gamma (768,)\n",
      "model.blocks.2.norm1.beta (768,)\n",
      "model.blocks.2.attn.q.bias (768,)\n",
      "model.blocks.2.attn.v.bias (768,)\n",
      "model.blocks.2.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.2.attn.relative_position_index (197, 197)\n",
      "model.blocks.2.attn.q.weight (768, 768)\n",
      "model.blocks.2.attn.k.weight (768, 768)\n",
      "model.blocks.2.attn.v.weight (768, 768)\n",
      "model.blocks.2.attn.proj.weight (768, 768)\n",
      "model.blocks.2.attn.proj.bias (768,)\n",
      "model.blocks.2.norm2.gamma (768,)\n",
      "model.blocks.2.norm2.beta (768,)\n",
      "model.blocks.2.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.2.mlp.fc1.bias (3072,)\n",
      "model.blocks.2.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.2.mlp.fc2.bias (768,)\n",
      "model.blocks.3.gamma_1 (768,)\n",
      "model.blocks.3.gamma_2 (768,)\n",
      "model.blocks.3.norm1.gamma (768,)\n",
      "model.blocks.3.norm1.beta (768,)\n",
      "model.blocks.3.attn.q.bias (768,)\n",
      "model.blocks.3.attn.v.bias (768,)\n",
      "model.blocks.3.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.3.attn.relative_position_index (197, 197)\n",
      "model.blocks.3.attn.q.weight (768, 768)\n",
      "model.blocks.3.attn.k.weight (768, 768)\n",
      "model.blocks.3.attn.v.weight (768, 768)\n",
      "model.blocks.3.attn.proj.weight (768, 768)\n",
      "model.blocks.3.attn.proj.bias (768,)\n",
      "model.blocks.3.norm2.gamma (768,)\n",
      "model.blocks.3.norm2.beta (768,)\n",
      "model.blocks.3.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.3.mlp.fc1.bias (3072,)\n",
      "model.blocks.3.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.3.mlp.fc2.bias (768,)\n",
      "model.blocks.4.gamma_1 (768,)\n",
      "model.blocks.4.gamma_2 (768,)\n",
      "model.blocks.4.norm1.gamma (768,)\n",
      "model.blocks.4.norm1.beta (768,)\n",
      "model.blocks.4.attn.q.bias (768,)\n",
      "model.blocks.4.attn.v.bias (768,)\n",
      "model.blocks.4.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.4.attn.relative_position_index (197, 197)\n",
      "model.blocks.4.attn.q.weight (768, 768)\n",
      "model.blocks.4.attn.k.weight (768, 768)\n",
      "model.blocks.4.attn.v.weight (768, 768)\n",
      "model.blocks.4.attn.proj.weight (768, 768)\n",
      "model.blocks.4.attn.proj.bias (768,)\n",
      "model.blocks.4.norm2.gamma (768,)\n",
      "model.blocks.4.norm2.beta (768,)\n",
      "model.blocks.4.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.4.mlp.fc1.bias (3072,)\n",
      "model.blocks.4.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.4.mlp.fc2.bias (768,)\n",
      "model.blocks.5.gamma_1 (768,)\n",
      "model.blocks.5.gamma_2 (768,)\n",
      "model.blocks.5.norm1.gamma (768,)\n",
      "model.blocks.5.norm1.beta (768,)\n",
      "model.blocks.5.attn.q.bias (768,)\n",
      "model.blocks.5.attn.v.bias (768,)\n",
      "model.blocks.5.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.5.attn.relative_position_index (197, 197)\n",
      "model.blocks.5.attn.q.weight (768, 768)\n",
      "model.blocks.5.attn.k.weight (768, 768)\n",
      "model.blocks.5.attn.v.weight (768, 768)\n",
      "model.blocks.5.attn.proj.weight (768, 768)\n",
      "model.blocks.5.attn.proj.bias (768,)\n",
      "model.blocks.5.norm2.gamma (768,)\n",
      "model.blocks.5.norm2.beta (768,)\n",
      "model.blocks.5.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.5.mlp.fc1.bias (3072,)\n",
      "model.blocks.5.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.5.mlp.fc2.bias (768,)\n",
      "model.blocks.6.gamma_1 (768,)\n",
      "model.blocks.6.gamma_2 (768,)\n",
      "model.blocks.6.norm1.gamma (768,)\n",
      "model.blocks.6.norm1.beta (768,)\n",
      "model.blocks.6.attn.q.bias (768,)\n",
      "model.blocks.6.attn.v.bias (768,)\n",
      "model.blocks.6.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.6.attn.relative_position_index (197, 197)\n",
      "model.blocks.6.attn.q.weight (768, 768)\n",
      "model.blocks.6.attn.k.weight (768, 768)\n",
      "model.blocks.6.attn.v.weight (768, 768)\n",
      "model.blocks.6.attn.proj.weight (768, 768)\n",
      "model.blocks.6.attn.proj.bias (768,)\n",
      "model.blocks.6.norm2.gamma (768,)\n",
      "model.blocks.6.norm2.beta (768,)\n",
      "model.blocks.6.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.6.mlp.fc1.bias (3072,)\n",
      "model.blocks.6.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.6.mlp.fc2.bias (768,)\n",
      "model.blocks.7.gamma_1 (768,)\n",
      "model.blocks.7.gamma_2 (768,)\n",
      "model.blocks.7.norm1.gamma (768,)\n",
      "model.blocks.7.norm1.beta (768,)\n",
      "model.blocks.7.attn.q.bias (768,)\n",
      "model.blocks.7.attn.v.bias (768,)\n",
      "model.blocks.7.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.7.attn.relative_position_index (197, 197)\n",
      "model.blocks.7.attn.q.weight (768, 768)\n",
      "model.blocks.7.attn.k.weight (768, 768)\n",
      "model.blocks.7.attn.v.weight (768, 768)\n",
      "model.blocks.7.attn.proj.weight (768, 768)\n",
      "model.blocks.7.attn.proj.bias (768,)\n",
      "model.blocks.7.norm2.gamma (768,)\n",
      "model.blocks.7.norm2.beta (768,)\n",
      "model.blocks.7.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.7.mlp.fc1.bias (3072,)\n",
      "model.blocks.7.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.7.mlp.fc2.bias (768,)\n",
      "model.blocks.8.gamma_1 (768,)\n",
      "model.blocks.8.gamma_2 (768,)\n",
      "model.blocks.8.norm1.gamma (768,)\n",
      "model.blocks.8.norm1.beta (768,)\n",
      "model.blocks.8.attn.q.bias (768,)\n",
      "model.blocks.8.attn.v.bias (768,)\n",
      "model.blocks.8.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.8.attn.relative_position_index (197, 197)\n",
      "model.blocks.8.attn.q.weight (768, 768)\n",
      "model.blocks.8.attn.k.weight (768, 768)\n",
      "model.blocks.8.attn.v.weight (768, 768)\n",
      "model.blocks.8.attn.proj.weight (768, 768)\n",
      "model.blocks.8.attn.proj.bias (768,)\n",
      "model.blocks.8.norm2.gamma (768,)\n",
      "model.blocks.8.norm2.beta (768,)\n",
      "model.blocks.8.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.8.mlp.fc1.bias (3072,)\n",
      "model.blocks.8.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.8.mlp.fc2.bias (768,)\n",
      "model.blocks.9.gamma_1 (768,)\n",
      "model.blocks.9.gamma_2 (768,)\n",
      "model.blocks.9.norm1.gamma (768,)\n",
      "model.blocks.9.norm1.beta (768,)\n",
      "model.blocks.9.attn.q.bias (768,)\n",
      "model.blocks.9.attn.v.bias (768,)\n",
      "model.blocks.9.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.9.attn.relative_position_index (197, 197)\n",
      "model.blocks.9.attn.q.weight (768, 768)\n",
      "model.blocks.9.attn.k.weight (768, 768)\n",
      "model.blocks.9.attn.v.weight (768, 768)\n",
      "model.blocks.9.attn.proj.weight (768, 768)\n",
      "model.blocks.9.attn.proj.bias (768,)\n",
      "model.blocks.9.norm2.gamma (768,)\n",
      "model.blocks.9.norm2.beta (768,)\n",
      "model.blocks.9.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.9.mlp.fc1.bias (3072,)\n",
      "model.blocks.9.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.9.mlp.fc2.bias (768,)\n",
      "model.blocks.10.gamma_1 (768,)\n",
      "model.blocks.10.gamma_2 (768,)\n",
      "model.blocks.10.norm1.gamma (768,)\n",
      "model.blocks.10.norm1.beta (768,)\n",
      "model.blocks.10.attn.q.bias (768,)\n",
      "model.blocks.10.attn.v.bias (768,)\n",
      "model.blocks.10.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.10.attn.relative_position_index (197, 197)\n",
      "model.blocks.10.attn.q.weight (768, 768)\n",
      "model.blocks.10.attn.k.weight (768, 768)\n",
      "model.blocks.10.attn.v.weight (768, 768)\n",
      "model.blocks.10.attn.proj.weight (768, 768)\n",
      "model.blocks.10.attn.proj.bias (768,)\n",
      "model.blocks.10.norm2.gamma (768,)\n",
      "model.blocks.10.norm2.beta (768,)\n",
      "model.blocks.10.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.10.mlp.fc1.bias (3072,)\n",
      "model.blocks.10.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.10.mlp.fc2.bias (768,)\n",
      "model.blocks.11.gamma_1 (768,)\n",
      "model.blocks.11.gamma_2 (768,)\n",
      "model.blocks.11.norm1.gamma (768,)\n",
      "model.blocks.11.norm1.beta (768,)\n",
      "model.blocks.11.attn.q.bias (768,)\n",
      "model.blocks.11.attn.v.bias (768,)\n",
      "model.blocks.11.attn.relative_position_bias_table (732, 12)\n",
      "model.blocks.11.attn.relative_position_index (197, 197)\n",
      "model.blocks.11.attn.q.weight (768, 768)\n",
      "model.blocks.11.attn.k.weight (768, 768)\n",
      "model.blocks.11.attn.v.weight (768, 768)\n",
      "model.blocks.11.attn.proj.weight (768, 768)\n",
      "model.blocks.11.attn.proj.bias (768,)\n",
      "model.blocks.11.norm2.gamma (768,)\n",
      "model.blocks.11.norm2.beta (768,)\n",
      "model.blocks.11.mlp.fc1.weight (3072, 768)\n",
      "model.blocks.11.mlp.fc1.bias (3072,)\n",
      "model.blocks.11.mlp.fc2.weight (768, 3072)\n",
      "model.blocks.11.mlp.fc2.bias (768,)\n",
      "model.fc_norm.gamma (768,)\n",
      "model.fc_norm.beta (768,)\n",
      "model.head.weight (1000, 768)\n",
      "model.head.bias (1000,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import mindspore\n",
    "from mindspore import Tensor, dtype\n",
    "from mindspore import save_checkpoint\n",
    "from mindspore import Parameter\n",
    "model = torch.load(\"beit_base_patch16_224_pt22k_ft22kto1k.pth\", map_location='cpu')['model']\n",
    "weights = []\n",
    "prefix = \"model.\"\n",
    "for key in model_keys:\n",
    "    name2weight = {}\n",
    "    if \"bn\" in key or \"norm\" in key or \"ln\" in key:\n",
    "        if \"weight\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\".weight\", \".gamma\")\n",
    "        elif \"bias\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\".bias\", \".beta\")\n",
    "        elif \"mean\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\"running_mean\", \"moving_mean\")\n",
    "        elif \"var\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\"running_var\", \"moving_variance\")\n",
    "        \n",
    "        name2weight[\"data\"] = Parameter(Tensor(model[key].numpy(), dtype.float32),requires_grad=True) \n",
    "        weights.append(name2weight)\n",
    "    elif \"qkv\" in key:\n",
    "        key_q = prefix +  key.replace(\"qkv\", \"q\")\n",
    "        key_k = prefix +  key.replace(\"qkv\", \"k\")\n",
    "        key_v = prefix + key.replace(\"qkv\", \"v\")\n",
    "        shape = model[key].shape[0]//3\n",
    "        weight = Parameter(Tensor(model[key].numpy(), dtype.float32),requires_grad=True) \n",
    "        weight_q = weight[:shape]\n",
    "        weight_k = weight[shape:shape*2]\n",
    "        weight_v = weight[shape*2:]\n",
    "        weights.append({\"name\":key_q, \"data\": weight_q})\n",
    "        weights.append({\"name\":key_k, \"data\": weight_k})\n",
    "        weights.append({\"name\":key_v, \"data\": weight_v})\n",
    "    elif \"q_bias\" in key:\n",
    "        name2weight[\"name\"] = prefix + key.replace(\"q_bias\", \"q.bias\")\n",
    "        name2weight[\"data\"] = Parameter(Tensor(model[key].numpy(), dtype.float32),requires_grad=True)\n",
    "        weights.append(name2weight)\n",
    "    elif \"v_bias\" in key:\n",
    "        name2weight[\"name\"] = prefix + key.replace(\"v_bias\", \"v.bias\")\n",
    "        name2weight[\"data\"] = Parameter(Tensor(model[key].numpy(), dtype.float32),requires_grad=True)\n",
    "        weights.append(name2weight)\n",
    "    else:\n",
    "        dd = dtype.float32\n",
    "        if \"relative_position_index\" in key:\n",
    "            dd = dtype.int32\n",
    "        weight = Parameter(Tensor(model[key].numpy(), dd),requires_grad=True)\n",
    "        key = prefix + key\n",
    "        weights.append({\"name\": key, \"data\": weight})\n",
    "weights_out = []\n",
    "for weight in weights:\n",
    "    weight_out = {}\n",
    "    name = weight[\"name\"]\n",
    "    weight_out[\"name\"] = name\n",
    "    weight_out[\"data\"] = weight[\"data\"]\n",
    "    weights_out.append(weight_out)\n",
    "    print(weight_out[\"name\"], weight_out['data'].shape)\n",
    "save_checkpoint(weights_out, \"beit_base_patch16_224_pt22k_ft22kto1k.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c78fa481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584be6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
